library(cluster, lib.loc = "C:/Program Files/R/R-3.6.2/library")
detach("package:cluster", unload = TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
#Compute Semi parameter S
S = 1/2*(length1 + length2 + length3)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('E:/HeronsFormula.R', echo=TRUE)
cls
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('C:/Users/HARRISON/Desktop/QuadraticFormula.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('C:/Users/HARRISON/Desktop/GradeGroup27.R', echo=TRUE)
v = c(1,2,3,4,5,6,7,8,9)
v
A = matrix(v,3,3)
A
A = matrix(v,3,3,byrow = TRUE)
A
seq(1,10,-2)
seq(1,10,2)
seq(10,1,2)
seq(10,1,-2)
A[1,2]
A ==1
Side = scan()
source('~/.active-rstudio-document', echo=TRUE)
A
adta = c(485,511,841,725,615,520,535,635,616)
t.test(adta,mu=700,conf.level = 0.95)
x=c(485,511,841,725,615,520,535,635,616)
t.test(x,mu=700)
t.test(x,mu=700,alt="two.sided")
t.test(x,mu=700,alt="less")
t.test(x,mu=700,alt=)
t.test(x,mu=700,alt="greater")
Beginning = c(76,52,78,80,67,65,72,57,82,88)
End = c(89,81,89,92,82,86,91,88,95,100)
t.test(Beginning,End,conf.level=0.95,paired = T,alt="greater")
nonSmokers = c(81,62,90,79,65,86,88,72,89,89,74,92,70,75,
88,77,87,76,90,45,61,69,87,75,94,69,95,70,98,61,66,91,81,72,72,73,70,77,84,67)
Smokers = c(72,86,77,66,80,35,87,79,63,78,77,67,67,72,65,65,69,
75,90,76,62,73,55,70,67,71,69,64,62,78,91,64,71,80,30,70,45,71)
wilcox.test(nonSmokers,Smokers,conf.level=0.99)
nonSmokers = c(81,62,90,79,65,86,88,72,89,89,74,92,70,75,
88,77,87,76,90,45,61,69,87,75,94,69,95,70,98,61,66,91,81,72,72,73,70,77,84,67)
Smokers = c(72,86,77,66,80,35,87,79,63,78,77,67,67,72,65,65,69,
75,90,76,62,73,55,70,67,71,69,64,62,78,91,64,71,80,30,70,45,71)
wilcox.test(nonSmokers,Smokers,conf.level=0.99,paired = F)
nonSmokers = c(81,62,90,79,65,86,88,72,89,89,74,92,70,75,
88,77,87,76,90,45,61,69,87,75,94,69,95,70,98,61,66,91,81,72,72,73,70,77,84,67)
Smokers = c(72,86,77,66,80,35,87,79,63,78,77,67,67,72,65,65,69,
75,90,76,62,73,55,70,67,71,69,64,62,78,91,64,71,80,30,70,45,71)
wilcox.test(nonSmokers,Smokers,conf.level=0.99,paired = T)
nonSmokers.length()
nonSmokers.length()
Drug_1 = c(78,65,63,44,50,78,70,61,50,44)
Drug_2 = c(71,66,56,40,55,31,45,66,47,42)
Drug_3 = c(57,88,58,78,65,61,62,44,48,77)
kruskal.test(list(Drug_1,Drug_2,Drug_3))
Drug_1 = c(78,65,63,44,50,78,70,61,50,44)
Drug_2 = c(71,66,56,40,55,31,45,66,47,42)
Drug_3 = c(57,88,58,78,65,61,62,44,48,77)
kruskal.test(Drug_1,Drug_2,Drug_3)
library(readxl)
EXAMS_data <- read_excel("C:/Users/perso/OneDrive/Desktop/EXAMS_data.xls")
View(EXAMS_data)
attach(EXAMS_data)
Maize
library(forecast,tseries)
library(tseries)
autoplot(Maize)
plot(Maize)
Maize.ts = ts(Maize, start = 1964,frequency = 1)
autoplot(Maize.ts)
adf.test(Maize.ts)
pp.test(Maize.ts)
kpss.test(Maize.ts)
maize.dif = diff(Maize.ts)
maize.dif
autoplot(maize.dif)
adf.test(maize.dif)
pp.test(maize.dif)
kpss.test(maize.dif)
auto.arima(maize.dif)
data1 = c(1,2,3,4,5,6,7,8)
length(data1)
data1 = c(1,2,3,4,5,6,7,8)
data2 = c(2,3,4,5,6,7,8,9)
model = lm(data1~data2)
summary(model)
install.packages("lubridate")
library(tseries)
library(FinTS)
library(lubridate)
library(forecast)
library(readxl)
AAPL <- read.csv("AAPL(1).csv")
AAPL <- read.csv("F:/Project/AAPL(1).csv")
AAPL <- read.csv("F:/Project/AAPL (1).csv")
AAPL
attach(AAPL)
AAPL.ts =ts(Open,
freq=365.25/7,
start=decimal_date(ymd("2013-3-18")))
AAPL.ts
ArchTest(AAPL.ts)
library(PerformanceAnalytics)
Returns = CalculateReturns(AAPL.ts, method = "log")
AAPL.ts = window(AAPL.ts)
Returns = CalculateReturns(AAPL.ts, method = "log")
AAPL.ts = window(AAPL.ts,freq=365.25/7,
start=decimal_date(ymd("2013-3-18")))
Returns = CalculateReturns(AAPL.ts, method = "log")
plot(AAPL.ts)
Returns = CalculateReturns(ts(AAPL.ts),method="log")
charts.TimeSeries(Returns)
plot(Returns)
Returns.train = Returns[1:419]
plot(Returns.train)
Returns.train = ts(Returns[1:419])
plot(Returns.train)
auto.arima(Returns.train)
auto.arima(Returns.train,stepwise = FALSE,approximation = FALSE)
library(tseries)
library(FinTS)
library(lubridate)
library(forecast)
library(readxl)
library(PerformanceAnalytics)
library(rugarch)
AAPL <- read.csv("F:/Project/AAPL (1).csv")
AAPL
attach(AAPL)
AAPL.ts =ts(Open,
freq=365.25/7,
start=decimal_date(ymd("2013-3-18")))
AAPL.ts
plot(AAPL.ts)
shapiro.test(AAPL.ts)
ArchTest(AAPL.ts)
Returns = CalculateReturns((AAPL.ts),method="log")
autoplot(Returns.ts,col="blue")
autoplot(Returns,col="blue")
Returns = CalculateReturns((AAPL.ts),method="log")
autoplot(Returns,col="blue")
plot(Returns)
AAPL.ts = window(AAPL.ts,freq=365.25/7,
start=decimal_date(ymd("2013-3-18")))
Returns = CalculateReturns((AAPL.ts),method="log")
autoplot(Returns,col="blue")
Returns
Returns = CalculateReturns(AAPL.ts,method="log")
library(PerformanceAnalytics)
Returns = CalculateReturns(AAPL.ts,method="log")
Returns = CalculateReturns(ts(AAPL.ts),method="log")
Returns
autoplot(Returns,col="blue")
plot(Returns)
Returns.train = Returns.ts[1:471] %>% ts ( freq=365.25/7,decimal_date(ymd("2013-3-18")) )
Returns.train = Returns[1:471] %>% ts ( freq=365.25/7,decimal_date(ymd("2013-3-18")) )
Returns.train
plot(Returns.train)
auto.arima(Returns.train,stepwise = FALSE,approximation = FALSE)
auto.arima(Returns.train,stepwise = FALSE,approximation = FALSE)
auto.arima(Returns.train)
library(tseries)
library(FinTS)
library(lubridate)
library(forecast)
library(readxl)
library(PerformanceAnalytics)
library(rugarch)
library(fpp2)
library(seastests)
AAPL <- read.csv("C:/Users/perso/OneDrive/Desktop/APPLE.csv")
AAPL
attach(AAPL)
AAPL.ts =ts(Open,
freq=365.25/7,
start=decimal_date(ymd("2013-01-01"))
)
AAPL.ts =ts(Close,
freq=365.25/7,
start=decimal_date(ymd("2013-01-01"))
)
AAPL.ts
summary(AAPL.ts)
autoplot(AAPL.ts,main = "Time Series Plot of Apple Inc Openning Stock Prices",
ylab = "Prices in USD", xlab = "Weeks")
rolling_var <- rollapply(AAPL.ts, width = 52, FUN = var, align = "right", by = 1)
plot(rolling_var, type = "l")
#Splitting Into Test and Train Sets
AAPL.train <- AAPL.ts[1:525] %>%
ts(frequency = 365.25/7 , start=decimal_date(ymd("2013-01-01")))
autoplot(AAPL.train,main="Train Time Series Plot of Apple Inc Openning Stock Prices",
xlab = "Weeks", ylab = "Prices in USD")
AAPL.test <- AAPL.ts[526:545] %>%
ts(frequency = 365.25/7 , start=decimal_date(ymd("2022-01-17")))
autoplot(AAPL.test,main="Test Time Series Plot of Apple Inc Openning Stock Prices",
xlab = "Weeks", ylab = "Prices in USD")
#Data is not stationary, number of differencing needed
ndiffs(AAPL.train)
#Transformation
lambdaValue = BoxCox.lambda(AAPL.train)
trAAPL.train = BoxCox(AAPL.train,lambda = lambdaValue)
lambdaValue
#Automatic Search for Suitable model
auto.arima(trAAPL.train,stepwise = FALSE,approximation = FALSE,trace = TRUE)
install.packages("ellipse")
install.packages("mvtnorm")
install.packages("mnormt")
install.packages("MVN")
library(tseries)
library(tseries)
library(MASS, lib.loc = "C:/Program Files/R/R-4.3.0/library")
library(MASS)
library(tseries)
setwd("~/")
Data.csv
library(readr)
library(readr)
data = read.csv("Data.csv")
load("C:/Users/perso/OneDrive/Desktop/ML/Data Preprocessing/dataPreprocessing.r")
setwd("C:/Users/perso/OneDrive/Desktop/ML/Classification/Kernel SVM")
#Import dataset
dataset = read.csv('Social_Network_Ads.csv')
#Splitting into test and train
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased,SplitRatio = 0.75)
trainSet = subset(dataset,split == TRUE)
testSet = subset(dataset,split == FALSE)
#Feature scaling
trainSet[,1:2] = scale(trainSet[,1:2])
View(dataset)
View(testSet)
View(testSet)
View(trainSet)
View(testSet)
testSet[,1:2] = scale(testSet[,1:2])
# Kernel SVM
library(e1071)
classifier = svm(formula= Purchased ~., data = trainSet,
type = 'C-classification',
kernel = 'radial')
#Predicting the testSet
classPred = predict(classifier,type = 'response', newdata = testSet[-3])
# Creating the confusion matrix
matrix = table(testSet[,3],classPred)
classPred
matrix
library(ElemStatLearn)
set = trainSet
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'dodgerblue', 'salmon'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'dodgerblue3', 'salmon3'))
library(ElemStatLearn)
set = testSet
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'dodgerblue', 'salmon'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'dodgerblue3', 'salmon3'))
